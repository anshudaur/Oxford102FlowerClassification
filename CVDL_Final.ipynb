{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CVDL-Final.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GKv3-x6HjAN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2b121196-b7ef-4142-f915-8ab9f0bb01b2"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import pathlib\n",
        "import matplotlib.pyplot as plt\n",
        "# tf.keras.backend.clear_session()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-_-ca6UHp2P",
        "colab_type": "code",
        "outputId": "d635da2d-6fa6-41a4-e2fd-c497566c701d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-sKOCDWHvUn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks\")\n",
        "data_dir_train=pathlib.Path('train')\n",
        "data_dir_valid=pathlib.Path('valid')\n",
        "data_dir_test=pathlib.Path('test')\n",
        "# image_count = len(list(data_dir.glob('*/*.jpg')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-EQYnXcH-fd",
        "colab_type": "code",
        "outputId": "7fb9bff2-934b-4411-dbce-c84c5a006d34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "\n",
        "image_generatorTest = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
        "image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rotation_range=10,width_shift_range=0.2,height_shift_range=0.1,shear_range=0.15,zoom_range=0.1,channel_shift_range=10,horizontal_flip=True, rescale=1./255)\n",
        "\n",
        "import numpy as np\n",
        "BATCH_SIZE = 64\n",
        "IMG_HEIGHT = 224\n",
        "IMG_WIDTH = 224\n",
        "# STEPS_PER_EPOCH = np.ceil(image_count/BATCH_SIZE)\n",
        "CLASS_NAMES = np.array([item.name for item in data_dir_train.glob('*')])\n",
        "CLASS_NAMES_VALID = np.array([item.name for item in data_dir_test.glob('*') ])\n",
        "print(CLASS_NAMES)\n",
        "print(CLASS_NAMES_VALID)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['68' '95' '59' '32' '35' '57' '61' '92' '66' '50' '34' '51' '60' '69'\n",
            " '56' '102' '94' '58' '93' '67' '29' '7' '18' '27' '9' '33' '20' '42' '11'\n",
            " '16' '6' '80' '45' '89' '17' '74' '73' '87' '1' '28' '10' '81' '8' '26'\n",
            " '86' '19' '72' '44' '21' '75' '43' '38' '31' '100' '65' '91' '36' '62'\n",
            " '88' '96' '98' '53' '30' '37' '55' '99' '39' '54' '52' '101' '97' '83'\n",
            " '64' '79' '41' '77' '63' '48' '46' '90' '85' '15' '4' '24' '3' '84' '23'\n",
            " '71' '12' '70' '78' '40' '47' '5' '76' '82' '13' '2' '14' '49' '22' '25']\n",
            "['98' '99' '97' '96' '95' '94' '9' '93' '90' '91' '92' '89' '87' '88' '86'\n",
            " '85' '83' '84' '78' '80' '77' '8' '82' '79' '81' '76' '74' '75' '67' '70'\n",
            " '72' '73' '69' '7' '71' '68' '66' '65' '64' '63' '58' '60' '59' '6' '57'\n",
            " '61' '56' '62' '54' '55' '52' '53' '50' '51' '49' '5' '48' '47' '45' '42'\n",
            " '43' '46' '44' '41' '40' '4' '39' '38' '37' '36' '33' '35' '30' '34' '3'\n",
            " '31' '29' '32' '27' '28' '24' '21' '23' '25' '2' '26' '20' '22' '19' '18'\n",
            " '17' '16' '12' '14' '13' '101' '100' '15' '102' '11' '1' '10']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YiBeJNuT0DPY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ls -lart valid/ "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcGQ8k0dIEH9",
        "colab_type": "code",
        "outputId": "ac4a725d-d1e9-4398-8129-9a89ed150b91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "train_data_gen = image_generator.flow_from_directory(directory=str(data_dir_train),\n",
        "                                                     batch_size=64,\n",
        "                                                     shuffle=True,\n",
        "                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                     class_mode='categorical')\n",
        "valid_data_gen = image_generatorTest.flow_from_directory(directory=str(data_dir_valid),\n",
        "                                                     batch_size=64,\n",
        "                                                     shuffle=True,\n",
        "                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                     class_mode='categorical')\n",
        "test_data_gen = image_generatorTest.flow_from_directory(directory=str(data_dir_test),\n",
        "                                                     batch_size=64,\n",
        "                                                     shuffle=False,\n",
        "                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                     class_mode='categorical')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 4938 images belonging to 102 classes.\n",
            "Found 1638 images belonging to 102 classes.\n",
            "Found 1638 images belonging to 102 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X36EqnolIHln",
        "colab_type": "code",
        "outputId": "cbe3a0c3-c6d2-4741-a71b-eb03d2dc69e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        }
      },
      "source": [
        "# import keras\n",
        "import tensorflow as tf\n",
        "# from tf.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "# from tensorflow.keras.layers.normalization import BatchNormalization\n",
        "import numpy as np\n",
        "#Instantiate an empty model\n",
        "model = tf.keras.Sequential()\n",
        "\n",
        "# 1st Convolutional Layer\n",
        "model.add(Conv2D(filters=64,input_shape=(224,224,3), kernel_size=(3,3),kernel_initializer='he_uniform' , padding='same', ))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(filters=64, kernel_size=(3,3),kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "# Max Pooling\n",
        "model.add(MaxPooling2D(pool_size=(2,2), padding='same'))\n",
        "\n",
        "\n",
        "# 2nd Convolutional Layer\n",
        "\n",
        "\n",
        "# 4th Convolutional Layer\n",
        "model.add(Conv2D(filters=128, kernel_size=(3,3),kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(filters=128, kernel_size=(3,3),kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "# Max Pooling\n",
        "model.add(MaxPooling2D(pool_size=(2,2), padding='same'))\n",
        "\n",
        "# 5th Convolutional Layer\n",
        "model.add(Conv2D(filters=256, kernel_size=(3,3),kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Conv2D(filters=256, kernel_size=(3,3),kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2), padding='same'))\n",
        "\n",
        "\n",
        "# Passing it to a Fully Connected layer\n",
        "model.add(Flatten())\n",
        "# 1st Fully Connected Layer\n",
        "model.add(Dense(256,kernel_initializer='he_uniform'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.2))\n",
        "# Add Dropout to prevent overfitting\n",
        "\n",
        "# Output Layer\n",
        "model.add(Dense(102))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()\n",
        "# lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(\n",
        "#   0.001,\n",
        "#   decay_steps=200*1000,\n",
        "#   decay_rate=1,\n",
        "#   staircase=False)\n",
        "# opt=tf.keras.optimizers.Adam(lr_schedule)\n",
        "sgd = tf.keras.optimizers.SGD(lr=0.001, momentum=0.9)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 224, 224, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 224, 224, 64)      0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 112, 112, 128)     0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 112, 112, 128)     0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 56, 56, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 56, 56, 256)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 200704)            0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               51380480  \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 102)               26214     \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 102)               0         \n",
            "=================================================================\n",
            "Total params: 52,552,102\n",
            "Trainable params: 52,552,102\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGSSrFrbIOm8",
        "colab_type": "code",
        "outputId": "ab686597-f3ae-438e-f4e8-447d2998680d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit_generator(\n",
        "    generator=train_data_gen,\n",
        "    validation_data=valid_data_gen,\n",
        "    steps_per_epoch=200,\n",
        "    epochs=100\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "200/200 [==============================] - 263s 1s/step - loss: 4.3598 - accuracy: 0.0533 - val_loss: 3.9501 - val_accuracy: 0.0971\n",
            "Epoch 2/100\n",
            "200/200 [==============================] - 262s 1s/step - loss: 3.8386 - accuracy: 0.1123 - val_loss: 3.4875 - val_accuracy: 0.1783\n",
            "Epoch 3/100\n",
            "200/200 [==============================] - 259s 1s/step - loss: 3.4534 - accuracy: 0.1727 - val_loss: 3.0429 - val_accuracy: 0.2564\n",
            "Epoch 4/100\n",
            "200/200 [==============================] - 255s 1s/step - loss: 3.1553 - accuracy: 0.2303 - val_loss: 2.8298 - val_accuracy: 0.2882\n",
            "Epoch 5/100\n",
            "200/200 [==============================] - 252s 1s/step - loss: 2.8676 - accuracy: 0.2858 - val_loss: 2.6345 - val_accuracy: 0.3492\n",
            "Epoch 6/100\n",
            "200/200 [==============================] - 256s 1s/step - loss: 2.6354 - accuracy: 0.3340 - val_loss: 2.2863 - val_accuracy: 0.4121\n",
            "Epoch 7/100\n",
            "200/200 [==============================] - 249s 1s/step - loss: 2.4633 - accuracy: 0.3679 - val_loss: 2.1191 - val_accuracy: 0.4621\n",
            "Epoch 8/100\n",
            "200/200 [==============================] - 259s 1s/step - loss: 2.3097 - accuracy: 0.3950 - val_loss: 2.0389 - val_accuracy: 0.4823\n",
            "Epoch 9/100\n",
            "200/200 [==============================] - 255s 1s/step - loss: 2.1277 - accuracy: 0.4386 - val_loss: 2.0202 - val_accuracy: 0.4799\n",
            "Epoch 10/100\n",
            "200/200 [==============================] - 254s 1s/step - loss: 2.0390 - accuracy: 0.4558 - val_loss: 2.0966 - val_accuracy: 0.4615\n",
            "Epoch 11/100\n",
            "200/200 [==============================] - 256s 1s/step - loss: 1.8639 - accuracy: 0.4992 - val_loss: 1.8019 - val_accuracy: 0.5256\n",
            "Epoch 12/100\n",
            "200/200 [==============================] - 254s 1s/step - loss: 1.7880 - accuracy: 0.5129 - val_loss: 1.8224 - val_accuracy: 0.5397\n",
            "Epoch 13/100\n",
            "200/200 [==============================] - 258s 1s/step - loss: 1.6345 - accuracy: 0.5486 - val_loss: 1.7096 - val_accuracy: 0.5604\n",
            "Epoch 14/100\n",
            "200/200 [==============================] - 257s 1s/step - loss: 1.5678 - accuracy: 0.5661 - val_loss: 1.6550 - val_accuracy: 0.5708\n",
            "Epoch 15/100\n",
            "200/200 [==============================] - 261s 1s/step - loss: 1.4502 - accuracy: 0.5989 - val_loss: 1.6477 - val_accuracy: 0.5678\n",
            "Epoch 16/100\n",
            "200/200 [==============================] - 259s 1s/step - loss: 1.3470 - accuracy: 0.6205 - val_loss: 1.5419 - val_accuracy: 0.5940\n",
            "Epoch 17/100\n",
            "200/200 [==============================] - 259s 1s/step - loss: 1.2547 - accuracy: 0.6403 - val_loss: 1.6054 - val_accuracy: 0.5855\n",
            "Epoch 18/100\n",
            "200/200 [==============================] - 259s 1s/step - loss: 1.2043 - accuracy: 0.6472 - val_loss: 1.7123 - val_accuracy: 0.5904\n",
            "Epoch 19/100\n",
            "200/200 [==============================] - 260s 1s/step - loss: 1.1406 - accuracy: 0.6704 - val_loss: 1.6715 - val_accuracy: 0.5775\n",
            "Epoch 20/100\n",
            "200/200 [==============================] - 261s 1s/step - loss: 1.0260 - accuracy: 0.6981 - val_loss: 1.7775 - val_accuracy: 0.5885\n",
            "Epoch 21/100\n",
            "200/200 [==============================] - 258s 1s/step - loss: 1.0124 - accuracy: 0.7013 - val_loss: 1.6433 - val_accuracy: 0.6038\n",
            "Epoch 22/100\n",
            "200/200 [==============================] - 260s 1s/step - loss: 0.8904 - accuracy: 0.7369 - val_loss: 1.6204 - val_accuracy: 0.6129\n",
            "Epoch 23/100\n",
            "200/200 [==============================] - 252s 1s/step - loss: 0.8539 - accuracy: 0.7420 - val_loss: 1.7736 - val_accuracy: 0.5891\n",
            "Epoch 24/100\n",
            "200/200 [==============================] - 265s 1s/step - loss: 0.7774 - accuracy: 0.7679 - val_loss: 1.6291 - val_accuracy: 0.6172\n",
            "Epoch 25/100\n",
            "200/200 [==============================] - 258s 1s/step - loss: 0.7431 - accuracy: 0.7806 - val_loss: 1.7355 - val_accuracy: 0.6001\n",
            "Epoch 26/100\n",
            "200/200 [==============================] - 258s 1s/step - loss: 0.7183 - accuracy: 0.7826 - val_loss: 1.6654 - val_accuracy: 0.6197\n",
            "Epoch 27/100\n",
            "200/200 [==============================] - 258s 1s/step - loss: 0.7080 - accuracy: 0.7841 - val_loss: 1.6340 - val_accuracy: 0.6288\n",
            "Epoch 28/100\n",
            "200/200 [==============================] - 259s 1s/step - loss: 0.6487 - accuracy: 0.8014 - val_loss: 1.5138 - val_accuracy: 0.6459\n",
            "Epoch 29/100\n",
            "200/200 [==============================] - 260s 1s/step - loss: 0.5451 - accuracy: 0.8318 - val_loss: 1.7090 - val_accuracy: 0.6398\n",
            "Epoch 30/100\n",
            "200/200 [==============================] - 258s 1s/step - loss: 0.5422 - accuracy: 0.8292 - val_loss: 1.6986 - val_accuracy: 0.6410\n",
            "Epoch 31/100\n",
            "  7/200 [>.............................] - ETA: 2:34 - loss: 0.5624 - accuracy: 0.8348"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-1ef1d66eaeea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_data_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m )\n",
            "\u001b[0;32m/tensorflow-2.0.0/python3.6/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1295\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1296\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1297\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m   1298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1299\u001b[0m   def evaluate_generator(self,\n",
            "\u001b[0;32m/tensorflow-2.0.0/python3.6/tensorflow_core/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.0.0/python3.6/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m    971\u001b[0m       outputs = training_v2_utils.train_on_batch(\n\u001b[1;32m    972\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m           class_weight=class_weight, reset_metrics=reset_metrics)\n\u001b[0m\u001b[1;32m    974\u001b[0m       outputs = (outputs['total_loss'] + outputs['output_losses'] +\n\u001b[1;32m    975\u001b[0m                  outputs['metrics'])\n",
            "\u001b[0;32m/tensorflow-2.0.0/python3.6/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m    262\u001b[0m       \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m       \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m       output_loss_metrics=model._output_loss_metrics)\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.0.0/python3.6/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, inputs, targets, sample_weights, output_loss_metrics)\u001b[0m\n\u001b[1;32m    309\u001b[0m           \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m           \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m           output_loss_metrics=output_loss_metrics))\n\u001b[0m\u001b[1;32m    312\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.0.0/python3.6/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36m_process_single_batch\u001b[0;34m(model, inputs, targets, output_loss_metrics, sample_weights, training)\u001b[0m\n\u001b[1;32m    266\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backwards\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaled_total_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m           \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaled_total_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m           if isinstance(model.optimizer,\n\u001b[1;32m    270\u001b[0m                         loss_scale_optimizer.LossScaleOptimizer):\n",
            "\u001b[0;32m/tensorflow-2.0.0/python3.6/tensorflow_core/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.0.0/python3.6/tensorflow_core/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     74\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
            "\u001b[0;32m/tensorflow-2.0.0/python3.6/tensorflow_core/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.0.0/python3.6/tensorflow_core/python/ops/nn_grad.py\u001b[0m in \u001b[0;36m_Conv2DGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m    576\u001b[0m   \u001b[0muse_cudnn_on_gpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"use_cudnn_on_gpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m   \u001b[0mdata_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data_format\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m   \u001b[0mshape_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape_n\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m   \u001b[0;31m# We call the gen_nn_ops backprop functions instead of nn_ops backprop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.0.0/python3.6/tensorflow_core/python/ops/array_ops.py\u001b[0m in \u001b[0;36mshape_n\u001b[0;34m(input, out_type, name)\u001b[0m\n\u001b[1;32m    503\u001b[0m   \"\"\"\n\u001b[1;32m    504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape_n\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.0.0/python3.6/tensorflow_core/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mshape_n\u001b[0;34m(input, out_type, name)\u001b[0m\n\u001b[1;32m   9032\u001b[0m       _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(\n\u001b[1;32m   9033\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thread_local_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ShapeN\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 9034\u001b[0;31m         name, _ctx._post_execution_callbacks, input, \"out_type\", out_type)\n\u001b[0m\u001b[1;32m   9035\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9036\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ej_A5GOwIZc-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('myModel.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btn020G9UK0Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.framework.test_util import is_gpu_available as tf\n",
        "if tf()==True:\n",
        "  device='/gpu:0'\n",
        "else:\n",
        "  device='/cpu:0'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYbE2QCvYnEq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model=tf.keras.models.load_model('myModel.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vv2nAXvtTBgR",
        "colab_type": "code",
        "outputId": "4a9e9385-bd1f-43ea-b009-9f41ad0f073e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model.evaluate_generator(test_data_gen)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.8555346498122582, 0.61904764]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPx9WxGgIXPi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "test_steps_per_epoch = np.math.ceil(test_data_gen.samples / test_data_gen.batch_size)\n",
        "\n",
        "predictions = model.predict_generator(test_data_gen, steps=test_steps_per_epoch)\n",
        "# Get most likely class\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpCOcN2bf7nH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3bc33a6e-e845-4031-a6fc-3be5c4862e8b"
      },
      "source": [
        "predicted_classes"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 30,   0,  72, ..., 101,  92,  48])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lCchiV2Tceq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "true_classes = test_data_gen.classes\n",
        "class_labels = list(test_data_gen.class_indices.keys()) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wd7O27PygBW8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# class_labels\n",
        "from sklearn import metrics"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ub2YsJQqIe0k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "06f9b3ea-b28b-4e02-d53a-fa4c3396fbdf"
      },
      "source": [
        "report = metrics.classification_report(true_classes, predicted_classes, target_names=class_labels)\n",
        "print(report)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.44      0.50      0.47         8\n",
            "          10       0.83      0.56      0.67         9\n",
            "         100       0.53      0.80      0.64        10\n",
            "         101       0.36      0.36      0.36        11\n",
            "         102       0.38      0.67      0.48         9\n",
            "          11       0.31      0.22      0.26        18\n",
            "          12       0.67      0.78      0.72        18\n",
            "          13       0.47      0.90      0.62        10\n",
            "          14       0.78      0.70      0.74        10\n",
            "          15       0.70      0.70      0.70        10\n",
            "          16       0.75      0.38      0.50         8\n",
            "          17       0.88      0.82      0.85        17\n",
            "          18       0.50      0.50      0.50        16\n",
            "          19       0.40      0.40      0.40        10\n",
            "           2       0.79      0.92      0.85        12\n",
            "          20       0.50      0.45      0.48        11\n",
            "          21       0.86      0.75      0.80         8\n",
            "          22       0.42      0.42      0.42        12\n",
            "          23       0.53      0.56      0.54        18\n",
            "          24       0.33      0.50      0.40         8\n",
            "          25       0.27      0.38      0.32         8\n",
            "          26       0.50      0.25      0.33         8\n",
            "          27       0.71      0.62      0.67         8\n",
            "          28       0.71      0.77      0.74        13\n",
            "          29       0.42      0.67      0.51        15\n",
            "           3       0.25      0.12      0.17         8\n",
            "          30       0.90      0.53      0.67        17\n",
            "          31       0.17      0.20      0.18        10\n",
            "          32       0.08      0.11      0.09         9\n",
            "          33       0.50      0.33      0.40         9\n",
            "          34       0.75      0.38      0.50         8\n",
            "          35       0.78      0.88      0.82         8\n",
            "          36       0.90      0.60      0.72        15\n",
            "          37       0.73      1.00      0.85        22\n",
            "          38       0.64      0.64      0.64        11\n",
            "          39       0.50      0.50      0.50         8\n",
            "           4       0.43      0.27      0.33        11\n",
            "          40       0.83      0.38      0.53        13\n",
            "          41       0.38      0.64      0.48        25\n",
            "          42       0.75      0.25      0.38        12\n",
            "          43       0.32      0.46      0.38        26\n",
            "          44       0.65      0.83      0.73        18\n",
            "          45       0.33      0.25      0.29         8\n",
            "          46       0.94      0.78      0.85        40\n",
            "          47       0.53      0.69      0.60        13\n",
            "          48       0.86      0.43      0.57        14\n",
            "          49       0.67      0.80      0.73        10\n",
            "           5       0.88      0.54      0.67        13\n",
            "          50       0.82      0.78      0.80        18\n",
            "          51       0.59      0.52      0.55        52\n",
            "          52       0.93      0.82      0.87        17\n",
            "          53       0.33      0.33      0.33        18\n",
            "          54       0.69      0.92      0.79        12\n",
            "          55       0.89      0.57      0.70        14\n",
            "          56       1.00      0.91      0.95        22\n",
            "          57       0.73      0.79      0.76        14\n",
            "          58       0.92      0.96      0.94        23\n",
            "          59       0.81      1.00      0.90        13\n",
            "           6       1.00      0.44      0.62         9\n",
            "          60       0.92      1.00      0.96        22\n",
            "          61       0.91      1.00      0.95        10\n",
            "          62       0.70      0.64      0.67        11\n",
            "          63       0.85      1.00      0.92        11\n",
            "          64       1.00      0.91      0.95        11\n",
            "          65       0.81      1.00      0.89        21\n",
            "          66       1.00      1.00      1.00        12\n",
            "          67       0.42      0.62      0.50         8\n",
            "          68       0.56      0.45      0.50        11\n",
            "          69       0.58      0.64      0.61        11\n",
            "           7       0.75      0.75      0.75         8\n",
            "          70       0.50      0.92      0.65        12\n",
            "          71       0.65      0.87      0.74        15\n",
            "          72       0.21      0.16      0.18        19\n",
            "          73       0.68      0.64      0.66        39\n",
            "          74       0.73      0.54      0.62        35\n",
            "          75       0.82      0.58      0.68        24\n",
            "          76       0.38      0.41      0.39        22\n",
            "          77       0.75      0.88      0.81        51\n",
            "          78       0.89      0.86      0.87        28\n",
            "          79       0.88      0.88      0.88         8\n",
            "           8       0.84      0.94      0.89        17\n",
            "          80       0.20      0.14      0.17        21\n",
            "          81       0.84      0.79      0.82        34\n",
            "          82       0.52      0.48      0.50        23\n",
            "          83       0.34      0.46      0.39        26\n",
            "          84       0.42      0.29      0.34        17\n",
            "          85       0.58      0.54      0.56        13\n",
            "          86       0.78      0.58      0.67        12\n",
            "          87       0.53      0.83      0.65        12\n",
            "          88       0.68      0.48      0.57        31\n",
            "          89       0.75      0.57      0.65        37\n",
            "           9       0.30      0.33      0.32         9\n",
            "          90       0.40      0.59      0.48        17\n",
            "          91       0.41      0.47      0.44        15\n",
            "          92       0.53      0.62      0.57        13\n",
            "          93       0.43      0.33      0.38         9\n",
            "          94       0.54      0.67      0.59        33\n",
            "          95       0.54      0.28      0.37        25\n",
            "          96       0.67      0.44      0.53        18\n",
            "          97       0.55      0.46      0.50        13\n",
            "          98       0.50      0.75      0.60        16\n",
            "          99       0.56      0.38      0.45        13\n",
            "\n",
            "    accuracy                           0.62      1638\n",
            "   macro avg       0.62      0.60      0.60      1638\n",
            "weighted avg       0.64      0.62      0.62      1638\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VgjkI-zIlCj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# confusion_matrix = metrics.precision_recall_fscore_support(y_true=true_classes, y_pred=predicted_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXVCk81ggiOX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4e26d2df-71a4-4a42-b442-9d4f920778b8"
      },
      "source": [
        "metrics.accuracy_score(true_classes,predicted_classes)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6190476190476191"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSUFpeTbgjao",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}